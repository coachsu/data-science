{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "302GngMZu08f",
        "CISX97ngNnT4",
        "la67XZ1Hnxg1",
        "VuEmtiBfVNPW"
      ],
      "authorship_tag": "ABX9TyOxwaubIwG21OopFyGQCUmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coachsu/data-science/blob/main/Unit02_Data_Collection_and_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collection and Preprocessing**\n",
        "## **Course:** Introduction to Big Data\n",
        "---\n",
        "> Wei-Tsung Su\n",
        "\n",
        ">*Department of Data Science, Soochow University, Taiwan*\n",
        "\n",
        "> **Last modified: 10/05/2023**"
      ],
      "metadata": {
        "id": "klthu1J2mkgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Purpose and Dataset Definition**"
      ],
      "metadata": {
        "id": "302GngMZu08f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of starting a data science project is criticial to data collection and its follow-up steps.\n",
        "\n",
        "In this early step, we should widely discuss with stakeholders\n",
        "\n",
        "* to understand the purpose. (problems to solve / 要解決什麼問題)\n",
        "* to develope requirements. (keys to problemsolving / 找出解決問題的關鍵)\n",
        "* to find potential data sources. (找出可能的資料來源)\n",
        "* to determine roles and responsibilies. (決定角色與責任)\n",
        "* to define data to collect. (定義要收集的資料)\n",
        "\n",
        "The following scenario is an example use case.\n",
        "\n",
        "## **Use case**\n",
        "---\n",
        "The dean (院長) attempts to find out that what kinds of students tend to apply departments (data science, applied statistics) of the college.\n",
        "\n",
        "Thus, the dean invites stakeholders, such as\n",
        "\n",
        "* **Director of computer center:** to get agreement of data collection\n",
        "* **Officers of amission division:** to discuss key attributes required in student recruitment\n",
        "* **Engineers of computer center:** to get dataset from the student record system\n",
        "* **Analysts of college:** to understand the requirements of dean\n",
        "\n",
        "In conclusion, engineers will obtain raw dataset from the student record system.\n",
        "\n",
        "However, since raw dataset has a lots of data and attributes unrelated to the purpose or are privacy-sensitive (e.g., name, phone, ...), enginners will remove these unrelated data and attributes first.\n",
        "\n",
        "According to the discussion, analysts need the dataset with attributes defined as follows.\n",
        "\n",
        "1. **id (string):** student identification (unique 5 digits)\n",
        "2. **department (string):** department\n",
        "3. **gender (string):** gender (\"M\" for male, \"F\" for female)\n",
        "4. **city (string):** city of residence\n",
        "5. **gpa (number):** grade point average (GPA) of mathematics (range: 0-15)\n",
        "\n",
        "The example data is\n",
        "\n",
        "|id|department|gender|city|gpa\n",
        "|----|----|----|----|----|\n",
        "|11201|Data Science|M|Taipei|6|\n",
        "|11202|Applied Statistics|F|New Taipei|5|\n",
        "\n",
        "----\n",
        "\n",
        "Now, we can proceed to data collection.  "
      ],
      "metadata": {
        "id": "QmoYuzf0sXMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Collection in Practice**"
      ],
      "metadata": {
        "id": "1KKgkwub0_Qt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A variety of methods, infrastures, and tools can be applied in data collection.\n",
        "\n",
        "In this practice, we will learn how to import data from the following sources and formats into computer for analysis with **[Python Pandas](https://pandas.pydata.org/)**.\n",
        "* **Data sources:** File, URL\n",
        "* **Data formats:** CSV, JSON\n",
        "\n",
        "The example dataset is defined as\n",
        "1. **name (string):** name\n",
        "2. **id (string):** student identification (unique 5 digits)\n",
        "3. **gender (string):** gender (\"M\" for male, \"F\" for female)\n",
        "4. **city (string):** city of residence\n",
        "5. **phone (string):** phone number\n",
        "6. **gpa (number):** grade point average (GPA) of mathematics (range: 0-15)\n",
        "7. **department (string):** department\n",
        "\n",
        "Before we can manipulate data with Pandas, we have to import Python packages.\n",
        "\n",
        "For example,\n",
        "* **Pandas** for data manipulation\n",
        "* **(Optional) Google Colab files** if you attemp to upload files to Google Colab"
      ],
      "metadata": {
        "id": "N5MqP-r7sdOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "WSKzgwhBc01x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1. Data Collection from File**"
      ],
      "metadata": {
        "id": "fg4UGRDYnn5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In most cases, dataset is one or multiple files. Thus, it is important to learn how to import file-based dataset into computer for analysis."
      ],
      "metadata": {
        "id": "FBpnGmiHXDYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***CSV file***"
      ],
      "metadata": {
        "id": "yctGffSdIfN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this practice, we will import CSV file into computer with Pandas.\n",
        "\n",
        "We have to first download dataset ([student.csv](https://github.com/coachsu/data-science/blob/main/dataset/student/students.csv)) and then upload it to Google Colab.\n",
        "\n",
        "After uploading dataset to Google Colab, we can convert CSV file into dataframe with **`Pandas.read_csv()`** function."
      ],
      "metadata": {
        "id": "9x8qxFxPWrqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload files to Google Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read CSV file and convert it to dataframe\n",
        "df = pd.read_csv(\"students.csv\")\n",
        "\n",
        "# Print whole dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "id": "8kkr8b8dig8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because dataset is typically large, printing whole dataframe is not a good data presentation for dataset verification.\n",
        "\n",
        "For dateset verification, **`DataFrame.head()`** or **`DataFrame.tail()`** functions are preferred instead of printing whole dataframe."
      ],
      "metadata": {
        "id": "XyljBruhJ6X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the first n rows of dataframe\n",
        "df.head(n = 2)"
      ],
      "metadata": {
        "id": "xWDWdtqYJWUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the last n rows of dataframe.\n",
        "df.tail(n = 2)"
      ],
      "metadata": {
        "id": "jfBOzZ27NHoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, we may need to check the data types of all columns with **`DataFrame.info()`** function."
      ],
      "metadata": {
        "id": "p2xU-nPFLM4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a concise summary of a DataFrame\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e1QzuKJxBNBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question:** What information the reslt of **`DataFrame.info()`** function can tells us? Why?"
      ],
      "metadata": {
        "id": "mSt96fYWMif0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**\n",
        "1. There is one missing data record. (only 16 non-null values in most columns)\n",
        "2. There is one data record with missing gender. (only 15 non-null values in gender column)\n",
        "3. Data type of id and phone columns is incorrect.\n",
        "\n"
      ],
      "metadata": {
        "id": "edY3naQ35B7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***JSON File***"
      ],
      "metadata": {
        "id": "CISX97ngNnT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this practice, you have to import **JSON file** into computer with **`Pandas.read_json()`** function as similar as CSV file.\n",
        "\n",
        "You can download JSON files for this practice as follows.\n",
        "\n",
        "* [students_array.json](https://github.com/coachsu/data-science/blob/main/dataset/student/students_array.json)\n",
        "* [students_object.json](https://github.com/coachsu/data-science/blob/main/dataset/student/students_object.json)"
      ],
      "metadata": {
        "id": "dmfSvbjEWoLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Playground to practice importing JSON file\n",
        "# Practice 1: Read JSON file and convert it to dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "l2VBTGwQiyjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 2: print the first 3 rows\n",
        "\n"
      ],
      "metadata": {
        "id": "3MVvCVd1LJM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 3: print the last 2 rows\n",
        "\n"
      ],
      "metadata": {
        "id": "Lx2I-4NgLPmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 4: check data types of all columns\n",
        "\n"
      ],
      "metadata": {
        "id": "_PjAkNyzLViX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example Program**"
      ],
      "metadata": {
        "id": "f_b2DkWU6hck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 1: Read JSON file and convert it to dataframe\n",
        "df = pd.read_json(\"students_object.json\")"
      ],
      "metadata": {
        "id": "VCm40h4b62SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 2: print the first 3 rows\n",
        "df.head(n = 3)"
      ],
      "metadata": {
        "id": "Q_TAL0aeAe0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 3: print the last 2 rows\n",
        "df.tail(n = 2)"
      ],
      "metadata": {
        "id": "pOI-OK-nAgVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 4: check data types of all column\n",
        "df.info()"
      ],
      "metadata": {
        "id": "aHWITlz6Aiog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2. Data Collection from URL**"
      ],
      "metadata": {
        "id": "la67XZ1Hnxg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, we have to access dataset via web application programming interface (API) by specifing uniform resource locator (URL).\n",
        "\n",
        "For example,\n",
        "\n",
        "* https://raw.githubusercontent.com/coachsu/data-science/main/dataset/student/students.csv\n",
        "* https://raw.githubusercontent.com/coachsu/data-science/main/dataset/student/students_array.json\n",
        "* https://raw.githubusercontent.com/coachsu/data-science/main/dataset/student/students_object.json"
      ],
      "metadata": {
        "id": "_RC9YpIzXI2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine data format from user input\n",
        "format = input('Data format (0 for CSV, 1 for JSON): ')\n",
        "# Convert string to integer\n",
        "format = int(format)\n",
        "\n",
        "# Get dataset URL from user input\n",
        "url = input('URL: ')\n",
        "\n",
        "# Read dataset from URL according to data format\n",
        "if format == 0: # CSV\n",
        "  print('Reading CSV file: {}'.format(url))\n",
        "  df = pd.read_csv(url)\n",
        "else: # JSON\n",
        "  print('Reading JSON file: {}'.format(url))\n",
        "  df = pd.read_json(url)\n",
        "\n",
        "# Print whole dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "id": "GHfztNFSjxZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Playground to practice importing dataset from URL\n",
        "# Practice 1: print the first 3 rows\n",
        "\n"
      ],
      "metadata": {
        "id": "Cpm73PCyj_Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 2: print the last 2 rows\n",
        "\n"
      ],
      "metadata": {
        "id": "NFnV0TwoN62f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 3: check data types of all columns"
      ],
      "metadata": {
        "id": "ZcZRKC6bN8fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Appendix 2.A. Data Collection from Other Sources**"
      ],
      "metadata": {
        "id": "lY6NsmAWmzNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***String***"
      ],
      "metadata": {
        "id": "VuEmtiBfVNPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Covert String to I/O stream\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "dGpT97dhVpri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV string\n",
        "csv_string = \"\"\"\n",
        "name,id,gender,department\n",
        ",11201,M,Data Science\n",
        "Alice,11202,F,Statistics\n",
        "John,11203,M,Computer Science\n",
        "\"\"\"\n",
        "csv_io = StringIO(csv_string)\n",
        "temp_df = pd.read_csv(csv_io)\n",
        "\n",
        "temp_df.head()"
      ],
      "metadata": {
        "id": "PB15_8MUjMnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read JSON string\n",
        "json_string = \"\"\"\n",
        "  [\n",
        "    {\"name\":\"Bob\", \"id\":\"11201\", \"gender\":\"M\", \"department\":\"Data Science\"},\n",
        "    {\"name\":\"Alice\", \"id\":\"11202\", \"gender\":\"F\", \"department\":\"Statistics\"},\n",
        "    {\"name\":\"John\", \"id\":\"11203\", \"gender\":\"M\", \"department\":\"Computer Science\"}\n",
        "  ]\n",
        "\"\"\"\n",
        "# json_string = \"\"\"\n",
        "#   {\n",
        "#     \"name\":[\"Bob\", \"Alice\", \"John\"],\n",
        "#     \"id\":[\"11201\", \"11202\", \"11203\"],\n",
        "#     \"gender\":[\"M\", \"F\", \"M\"],\n",
        "#     \"department\":[\"Data Science\", \"Statistics\", \"Computer Science\"]\n",
        "\n",
        "#   }\n",
        "# \"\"\"\n",
        "\n",
        "json_io = StringIO(json_string)\n",
        "temp_df = pd.read_json(json_io)\n",
        "\n",
        "temp_df.head()"
      ],
      "metadata": {
        "id": "U7AgVI48e49D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Python Dictionary***"
      ],
      "metadata": {
        "id": "ZOSAf9frndmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read JSON from dictionary\n",
        "json_dict = [\n",
        "    {\"name\":\"Bob\", \"id\":\"11201\", \"gender\":\"M\", \"department\":\"Data Science\"},\n",
        "    {\"name\":\"Alice\", \"id\":\"11202\", \"gender\":\"F\", \"department\":\"Applied Statistics\"},\n",
        "    {\"name\":\"John\", \"id\":\"11203\", \"gender\":\"M\", \"department\":\"Computer Science\"}\n",
        "  ]\n",
        "\n",
        "temp_df = pd.DataFrame.from_dict(json_dict)\n",
        "\n",
        "temp_df.head()"
      ],
      "metadata": {
        "id": "J8ldjofXfSfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Dataset Inspection in Practice**"
      ],
      "metadata": {
        "id": "RnxGI9CLWyPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once dataset has been imported into computer with Pandas, we can inspect the dataset before getting into next steps.\n",
        "\n",
        "The preliminary dataset inspection can involve several checks.\n",
        "\n",
        "For example,\n",
        "* **Format:** Is the dataset in the expected format?\n",
        "* **Attributes:** Are the required attributes present?\n",
        "* **Quality:** Is there any empty data? Is data correct?\n",
        "* ..."
      ],
      "metadata": {
        "id": "ErGun8oOs4Gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. Format Inspection**"
      ],
      "metadata": {
        "id": "hE3K-dG6aj1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Shape of dataset***\n",
        "\n",
        "We can get the shape of dataset to understand the total size of data and the total number of columns with **`DataFrame.shape()`** function."
      ],
      "metadata": {
        "id": "BLvxvd3iSQG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"students.csv\")\n",
        "df.head(n = 3)"
      ],
      "metadata": {
        "id": "_J5hnLrvXLCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return a tuple representing the dimensionality of the DataFrame.\n",
        "df.shape"
      ],
      "metadata": {
        "id": "RkkPpuLvfIX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result (***r***, c) indicates that the dataset\n",
        "* has ***r*** rows (number of data records)\n",
        "* has ***c*** columns (attributes)"
      ],
      "metadata": {
        "id": "lihvguhURoi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Correctness of column labels***\n",
        "\n",
        "The correctness of column labels is important.\n",
        "\n",
        "We cannot access columns with Pandas if specifying incorrect labels.\n",
        "\n",
        "For example,\n",
        "\n",
        "* **`'gender'`** and **`' gender'`** are two different labels of columns.\n",
        "* **`'name'`** and **`'Name'`** are two different labels of columns.\n",
        "\n",
        "Thus, we cannot access column **`'name'`** with label **`'Name'`** with Pandas."
      ],
      "metadata": {
        "id": "jFripCKXOcQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the column labels of dataframe\n",
        "df.columns"
      ],
      "metadata": {
        "id": "nYzk5pm1nR0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return column data with specifiying label 'name'\n",
        "df.name"
      ],
      "metadata": {
        "id": "7t0CuMtIRNA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return column data with specifiying label 'id' in the other format\n",
        "df['id']"
      ],
      "metadata": {
        "id": "zofpvGiTP4UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return error because of specifying incorrect label\n",
        "df.Name"
      ],
      "metadata": {
        "id": "6PO8qTQbRRjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case we attempt to change column labels, **`DataFrame.columns.str.replace()`** function can be used."
      ],
      "metadata": {
        "id": "WbGc-JbwP3U6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change column label from 'name' to 'Name'\n",
        "df.columns = df.columns.str.replace('name', 'Name')\n",
        "df.columns"
      ],
      "metadata": {
        "id": "7nz3xkUDohpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(n = 3)"
      ],
      "metadata": {
        "id": "hY6rR4Q8pksj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change column label from 'name' to 'Name'\n",
        "df.columns = df.columns.str.replace('Name', 'name')\n",
        "df.columns"
      ],
      "metadata": {
        "id": "ZmxlI_i1Qz0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. Quality Inspection**"
      ],
      "metadata": {
        "id": "TP7c7e4RTX8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Detecting missing value***"
      ],
      "metadata": {
        "id": "Qh0JapSuVUYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`DataFrame.count()`** function can help to detect if there is any missing value."
      ],
      "metadata": {
        "id": "KGcGM2pETDpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count non-NA cells for each column\n",
        "df.count()"
      ],
      "metadata": {
        "id": "KzZSggWQkoCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1:** One data record may be missing. Why?\n",
        "\n",
        "**Question 2:** One data record may have missing value of olumn 'gender'. Why?"
      ],
      "metadata": {
        "id": "lUXTQnDhTyUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, we can locate the missing values with **`DataFrame.isna()`** function."
      ],
      "metadata": {
        "id": "_xzpa0kXV9Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect location of missing values\n",
        "df.isna()"
      ],
      "metadata": {
        "id": "HABEzGJclm1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Checking correctness of dataset***"
      ],
      "metadata": {
        "id": "pvvnVQo7VQaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of distinct values for each column\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "OYMGVTPWgDti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What information the reslt of **`DataFrame.nunique()`** function can tells us? Why?"
      ],
      "metadata": {
        "id": "tz88xNfxVzO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Preview descriptive statistics***"
      ],
      "metadata": {
        "id": "-EPZYTLluf7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With **`DataFrame.describe()`** function, a descriptive statistics for numeric columns will be generated."
      ],
      "metadata": {
        "id": "8EtZrU-YXWKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate descriptive statistics for numeric columns\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "RU-BsqZ7kHs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Checking Data Type***"
      ],
      "metadata": {
        "id": "ERUnsS-PuvdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data type for each column can be checked with **`DataFrame.info()`** function."
      ],
      "metadata": {
        "id": "mRjb1VWJX1ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "LwWpnHZKYKq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case of data type is incorrect, we can change data type with **`DataFrame.astype()`** function."
      ],
      "metadata": {
        "id": "_mvvB0u3YOf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change data type of column\n",
        "df.id = df.id.astype(str)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "vkZjggCPq5cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(n = 3)"
      ],
      "metadata": {
        "id": "mgdpCSlm6wb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the best practice is specifed data type for columns while reading data."
      ],
      "metadata": {
        "id": "c8ynGB-0u6DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file with specifed data types for columns\n",
        "df = pd.read_csv(\"students.csv\", dtype={'id': str, 'phone': str})\n",
        "df.head(n = 3)"
      ],
      "metadata": {
        "id": "kfov3A6xrnFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "5N87fAOzYukg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Dataset Preprocessing"
      ],
      "metadata": {
        "id": "ns4IoqdeWjFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Continues with previous use case, engineers obtain raw data and then have to remove unrelated attributes and data.\n",
        "\n",
        "The raw dataset is defined as\n",
        "\n",
        "1. **name (string):** name\n",
        "2. **id (string):** student identification (unique 5 digits)\n",
        "3. **gender (string):** gender (\"M\" for male, \"F\" for female)\n",
        "4. **city (string):** city of residence\n",
        "5. **phone (string):** phone number\n",
        "6. **gpa (number):** grade point average (GPA) of mathematics (range: 0-15)\n",
        "7. **department (string):** department\n",
        "\n",
        "The reauired dataset is defined as\n",
        "\n",
        "1. **id (string):** student identification (unique 5 digits)\n",
        "2. **department (string):** department\n",
        "3. **gender (string):** gender (\"M\" for male, \"F\" for female)\n",
        "4. **city (string):** city of residence\n",
        "5. **gpa (number):** grade point average (GPA) of mathematics (range: 0-15)\n",
        "\n",
        "Thus, before transfering dataset to analysts, engineers need\n",
        "* to remove unrelated attributes, such as name, phone\n",
        "* to remove unrelated data, such as students not in department of data science and applied statistics."
      ],
      "metadata": {
        "id": "gPkGEfjjW7Ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1. Remove Unrelated Attributes**"
      ],
      "metadata": {
        "id": "y7YkyzO_QE6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fisrt, engineers need to remove unrelated attributes with `DataFrame.drop()` function."
      ],
      "metadata": {
        "id": "qoE5Ut7wY3hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(n = 3)"
      ],
      "metadata": {
        "id": "BvEs-891RNCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with given lables\n",
        "dfWithoutNameAndPhone = df.drop(columns = ['name','phone']) # same as df.drop(labels = ['name','phone'], axis = 1)\n",
        "dfWithoutNameAndPhone.head(n = 3)"
      ],
      "metadata": {
        "id": "KJih7ShbQOMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2. Remove Unrelated Data**\n",
        "Second, engineers need to remove unrelated data with `DataFrame.drop()` function."
      ],
      "metadata": {
        "id": "BsJDRxAmRS9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfWithoutNameAndPhone.head(n = 20)"
      ],
      "metadata": {
        "id": "Pj40QpANUU83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain sub-dataframe with data which meets specified conditions\n",
        "unrelated_df = dfWithoutNameAndPhone[\n",
        "    (dfWithoutNameAndPhone.department != 'Data Science') &\n",
        "    (dfWithoutNameAndPhone.department != 'Applied Statistics')\n",
        "     ]\n",
        "unrelated_df.head(n = 20)"
      ],
      "metadata": {
        "id": "g1zlTJ97nwSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index of unrelated data\n",
        "index = unrelated_df.index\n",
        "print(index)"
      ],
      "metadata": {
        "id": "KLb2H6SIRXhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index of data that meets specified conditions\n",
        "dfWithinCollege = dfWithoutNameAndPhone.drop(labels = index) # same as df.drop(labels = index, axis = 0)\n",
        "dfWithinCollege.head(n = 20)"
      ],
      "metadata": {
        "id": "Dy6heCEzo5sC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}